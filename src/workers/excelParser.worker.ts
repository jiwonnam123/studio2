
// src/workers/excelParser.worker.ts
import * as XLSX from 'xlsx';
import type { WorkerParseRequest, WorkerParseResponse } from '@/types/inquiry';

const PREVIEW_ROWS_LIMIT = 20; // ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜ ì œí•œ (í—¤ë” ì œì™¸í•˜ê³  ë°ì´í„° í–‰ë§Œ)
const EXPECTED_COLUMNS = 6;
const customColumnHeaders = [
  "ìº í˜ì¸ í‚¤", "ìº í˜ì¸ ëª…", "ADID / IDFA",
  "ì´ë¦„", "ì—°ë½ì²˜", "ë¹„ê³ "
];

self.onmessage = async (event: MessageEvent<WorkerParseRequest>) => {
  console.log("ğŸ”§ [Worker] 1. ë©”ì‹œì§€ ìˆ˜ì‹ ë¨", { timestamp: performance.now(), data: event.data });
  
  const { file } = event.data;
  const startTime = performance.now();
  const fileSize = file.size;
  const isLargeFile = fileSize > 5 * 1024 * 1024; // 5MB

  console.log("ğŸ”§ [Worker] 2. íŒŒì¼ í¬ê¸°:", fileSize, "bytes. ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—¬ë¶€:", isLargeFile);
  if (fileSize > 1024 * 1024) { // 1MB
    console.warn("ğŸ”§ [Worker] ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€ (1MB ì´ìƒ):", fileSize, "bytes");
  }

  self.postMessage({ type: 'progress', stage: 'received', progress: 10, fileSize } as WorkerParseResponse);

  let response: Omit<WorkerParseResponse, 'type' | 'stage' | 'progress'> = { // type, stage, progressëŠ” ìµœì¢… ì‘ë‹µì— í•„ìš” ì—†ìŒ
    success: false,
    error: null,
    previewData: null,
    fullData: null,
    totalDataRows: 0,
    headersValid: false,
    dataExistsInSheet: false,
    fileSize,
    processingTime: 0,
    isLargeFile,
  };

  /*
  // ìµœí›„ ìˆ˜ë‹¨: íŒŒì¼ í¬ê¸°ê°€ 500KBë¥¼ ì´ˆê³¼í•˜ë©´ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
  if (file.size > 500 * 1024) { // 500KB
    console.warn("ğŸ”§ [Worker] íŒŒì¼ í¬ê¸° ì´ˆê³¼ (500KB). ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.");
    response.error = "íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 500KB ì´í•˜ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.";
    response.success = false;
    response.processingTime = performance.now() - startTime;
    self.postMessage({ ...response, type: 'result' });
    return;
  }
  */

  try {
    console.log("ğŸ”§ [Worker] 3. arrayBuffer ì‹œì‘", performance.now());
    self.postMessage({ type: 'progress', stage: 'reading_file_start', progress: 20, fileSize } as WorkerParseResponse);
    const arrayBuffer = await file.arrayBuffer();
    console.log("ğŸ”§ [Worker] 4. arrayBuffer ì™„ë£Œ", performance.now());
    self.postMessage({ type: 'progress', stage: 'reading_file_done', progress: 30, fileSize } as WorkerParseResponse);

    console.log("ğŸ”§ [Worker] 5. XLSX.read ì‹œì‘", performance.now());
    self.postMessage({ type: 'progress', stage: 'xlsx_read_start', progress: 40, fileSize } as WorkerParseResponse);
    
    const workbook = XLSX.read(arrayBuffer, {
      type: 'array',
      cellStyles: false,
      cellFormula: false,
      cellHTML: false,
      cellNF: false, 
      cellDates: false,
      dense: true, 
      bookVBA: false,
      // bookSheets: false, // ì´ ì˜µì…˜ ì œê±° ë˜ëŠ” trueë¡œ ì„¤ì •í•´ì•¼ ì‹œíŠ¸ ë‚´ìš© íŒŒì‹± ê°€ëŠ¥
      bookProps: false,
      sheetStubs: false,
      raw: true 
    });
    console.log("ğŸ”§ [Worker] 6. XLSX.read ì™„ë£Œ", performance.now());
    self.postMessage({ type: 'progress', stage: 'xlsx_read_done', progress: 60, fileSize } as WorkerParseResponse);

    const firstSheetName = workbook.SheetNames[0];
    if (!firstSheetName) {
      response.error = "[Worker] No sheets found in the Excel file.";
      throw new Error(response.error);
    }
    const worksheet = workbook.Sheets[firstSheetName];
    if (!worksheet) {
      response.error = "[Worker] First Excel Sheet is empty or unreadable.";
      throw new Error(response.error);
    }

    console.log("ğŸ”§ [Worker] 7. sheet_to_json (ë°ì´í„° ì¶”ì¶œ) ì‹œì‘", performance.now());
    self.postMessage({ type: 'progress', stage: 'data_extraction_start', progress: 70, fileSize } as WorkerParseResponse);
    
    const allDataWithHeader: string[][] = XLSX.utils.sheet_to_json<string[]>(worksheet, {
      header: 1,
      blankrows: false,
      defval: '', 
      dense: true, 
    });
    console.log("ğŸ”§ [Worker] 8. sheet_to_json (ë°ì´í„° ì¶”ì¶œ) ì™„ë£Œ", performance.now());
    self.postMessage({ type: 'progress', stage: 'data_extraction_done', progress: 80, fileSize } as WorkerParseResponse);

    if (!allDataWithHeader || allDataWithHeader.length === 0) {
      response.error = "[Worker] The file is empty or contains no data rows (after sheet_to_json).";
      response.previewData = [customColumnHeaders]; // í—¤ë”ë§Œ ìˆëŠ” ë¯¸ë¦¬ë³´ê¸°
      response.headersValid = false; // í—¤ë”ë„ ì—†ë‹¤ê³  ê°„ì£¼
      response.fullData = [];
      response.totalDataRows = 0;
      response.dataExistsInSheet = false;
    } else {
      const headersFromSheet = allDataWithHeader[0]?.map(header => String(header || '').trim()) || [];
      
      if (headersFromSheet.length === EXPECTED_COLUMNS &&
          customColumnHeaders.every((ch, index) => headersFromSheet[index] === ch)) {
        response.headersValid = true;
        
        const dataRowsOnly = allDataWithHeader.slice(1);
        
        response.fullData = dataRowsOnly.map(row => {
            const newRow = Array(EXPECTED_COLUMNS).fill('');
            for (let i = 0; i < EXPECTED_COLUMNS; i++) {
                if (row[i] !== undefined && row[i] !== null) {
                    newRow[i] = String(row[i]);
                }
            }
            return newRow;
        }).filter(row => row.some(cell => cell.trim() !== ''));

        response.totalDataRows = response.fullData.length;
        response.dataExistsInSheet = response.totalDataRows > 0;

        if (!response.dataExistsInSheet && response.headersValid) {
          response.error = "[Worker] Headers are valid, but no actual data rows were found beneath them.";
        }
        
        response.previewData = [customColumnHeaders, ...(response.fullData || []).slice(0, PREVIEW_ROWS_LIMIT)];
      } else {
        response.headersValid = false;
        const foundHeadersPreview = headersFromSheet.slice(0, EXPECTED_COLUMNS + 2).join(", ");
        response.error = `[Worker] Invalid headers. Expected ${EXPECTED_COLUMNS} columns: "${customColumnHeaders.join(", ")}". Found ${headersFromSheet.length} columns, starting with: "${foundHeadersPreview}". Please use the provided template.`;
        
        const originalPreviewWithPossibleWrongHeader = allDataWithHeader.slice(0, PREVIEW_ROWS_LIMIT + 1);
        response.previewData = originalPreviewWithPossibleWrongHeader.map(row => {
             const newRow = Array(Math.max(EXPECTED_COLUMNS, row.length)).fill('');
             row.forEach((cell, i) => newRow[i] = String(cell || ''));
             return newRow;
        });
        response.dataExistsInSheet = false; 
        response.fullData = null;
        response.totalDataRows = 0;
      }
    }
    
    response.success = response.headersValid && response.dataExistsInSheet && !response.error;

  } catch (e: any) {
    console.error("ğŸ”§ [Worker] ì—ëŸ¬ ë°œìƒ (íŒŒì‹± ì¤‘):", e);
    response.error = response.error || `[Worker] Error parsing file: ${e.message || 'Unknown error during parsing'}`;
    response.success = false;
    response.fullData = null;
    response.dataExistsInSheet = false;
    response.totalDataRows = 0;
    if (!response.previewData && file) { 
        response.previewData = [customColumnHeaders]; 
    }
  } finally {
    response.processingTime = performance.now() - startTime;
    console.log("ğŸ”§ [Worker] 9. íŒŒì‹± ìµœì¢… ì™„ë£Œ ë° ê²°ê³¼ ì „ì†¡ ì§ì „", { timestamp: performance.now(), response });
    self.postMessage({ ...response, type: 'result' } as WorkerParseResponse); 
  }
};
